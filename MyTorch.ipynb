{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMypJjJDoC0YOcxtqqMJn4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattbarrett98/mikit-learn/blob/main/MyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHSiauXxZMNg"
      },
      "source": [
        "Classification project on MNIST handwritten digits dataset. We will try to code all algorithms from scratch- everything from k nearest neighbours to convolutional neural networks with batch normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "WSAe-Bm7SFLf",
        "outputId": "d685aec4-29a2-47f8-f549-251278f7fcc8"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import random as rnd\n",
        "from numpy.random import normal as norm\n",
        "\n",
        "#load data and plot first 4 images\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "for i in range(4):  \n",
        "  pyplot.subplot(330 + 1 + i)\n",
        "  pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n",
        "  pyplot.show()\n",
        "\n",
        "#divide by 255 to normalise to [0,1] to ensure all variables on the same scale\n",
        "traindata = (train_X/255).reshape(60000, 784)\n",
        "testdata = (test_X/255).reshape(10000, 784) \n",
        "\n",
        "#one hot encoding is necessary for certain algorithms\n",
        "Y = np.zeros((traindata.shape[0],len(set(train_y))))\n",
        "for i in range(len(Y)):\n",
        "  Y[i, train_y[i]]=1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUNB6Zv-XLZK"
      },
      "source": [
        "6 Multilayer perceptron\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1fhFeTjXQIh",
        "outputId": "86dc08c0-f6a6-44e2-8a3e-e2cea895b952"
      },
      "source": [
        "def softmax(x):\n",
        "  p = np.exp(x)\n",
        "  return p / np.sum(p, axis=0)\n",
        "\n",
        "def relu(x):\n",
        "  return (x + abs(x))/2  \n",
        "\n",
        "#2 hidden layers so we have 3 sets of weights and biases\n",
        "def mlp_grad(batch, truth, w1, w2, w3, b1, b2, b3):\n",
        "  z1 = np.matmul(w1, batch) + b1[:,np.newaxis]\n",
        "  a1 = relu(z1)\n",
        "  z2 = np.matmul(w2, a1) + b2[:,np.newaxis]\n",
        "  a2 = relu(z2)\n",
        "  #output of neural network\n",
        "  a3 = softmax(np.matmul(w3, a2) + b3[:,np.newaxis])\n",
        "  #calculate gradients using the chain rule/backpropogation - categorical cross entropy is our loss\n",
        "  inter1 = a3 - truth\n",
        "  grad_b3 = np.sum(inter1, axis=1)\n",
        "  grad_w3 = np.matmul(inter1, a2.T)\n",
        "  inter2 = np.matmul(w3.T, inter1) * np.sign(a2)\n",
        "  grad_b2 = np.sum(inter2, axis=1)\n",
        "  grad_w2 = np.matmul(inter2, a1.T)\n",
        "  inter3 = np.matmul(w2.T, inter2) * np.sign(a1)\n",
        "  grad_b1 = np.sum(inter3, axis=1)\n",
        "  grad_w1 = np.matmul(inter3, batch.T)\n",
        "  return grad_w1, grad_w2, grad_w3, grad_b1, grad_b2, grad_b3\n",
        "\n",
        "#basic gradient descent algorithm  \n",
        "def gradient_descent(batch,truth, par, learning_rate):\n",
        "  grad = mlp_grad(batch, truth, par[0], par[1], par[2], par[3], par[4], par[5])\n",
        "  par = [a - learning_rate*b for a,b in zip(par,grad)]\n",
        "  return par \n",
        "\n",
        "def mini_batch_sgd(X, Y, epochs, batch_size, l2, l3, l4):\n",
        "  #He initialisation since we are using relu activations\n",
        "  par = [np.random.normal(0, np.sqrt(1/X.shape[0]), (l2,X.shape[0])), np.random.normal(0, np.sqrt(2/l2), (l3,l2)), np.random.normal(0, np.sqrt(2/l3), (l4,l3)), np.zeros(l2), np.zeros(l3), np.zeros(l4)]\n",
        "  #loop through entire dataset 'epochs' times\n",
        "  for i in range(epochs):\n",
        "    #in each epoch perform gradient descent on each mini batch\n",
        "    for j in range(int(np.ceil(X.shape[1]/batch_size))):\n",
        "      batch = X[:, batch_size*j:batch_size*(j+1)]\n",
        "      truth = Y[:, batch_size*j:batch_size*(j+1)]\n",
        "      par = gradient_descent(batch, truth, par, 0.01)\n",
        "  return par[0], par[1], par[2], par[3], par[4], par[5]\n",
        "\n",
        "#train network\n",
        "a,b,c,d,e,f = mini_batch_sgd(traindata.T, Y.T, 30, 16, 128, 64, 10)\n",
        "\n",
        "#make predictions and output accuracy\n",
        "z1 = np.matmul(a, testdata.T) + d[:,np.newaxis]\n",
        "a1 = relu(z1)\n",
        "z2 = np.matmul(b, a1) + e[:,np.newaxis]\n",
        "a2 = relu(z2)\n",
        "a3 = softmax(np.matmul(c, a2) + f[:,np.newaxis])\n",
        "sum(np.argmax(a3, axis=0)==test_y)/test_y.shape[0]  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9765"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avEgnbKFep_G"
      },
      "source": [
        "check tensorflow gives a similar result (architecture is the same as is epochs, batch size etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCZVHPPI4Zzo",
        "outputId": "975f6ab4-2470-497e-a196-fb523f29dbf2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=784, activation='relu'))\n",
        "model.add(Dense(64, 'relu'))\n",
        "model.add(Dense(10, 'softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='SGD')\n",
        "model.fit(traindata, Y, epochs=30, batch_size=16, verbose=0)\n",
        "pred = model.predict(testdata)\n",
        "sum(np.argmax(np.array(pred), axis=1)==test_y)/test_y.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9778"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9etuRBylY2fK"
      },
      "source": [
        "7 Convolutional neural network (with batch normalisation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GvPsT9JY14d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf44a79-a712-464e-9df3-170d922f285c"
      },
      "source": [
        "#cnn architecture: conv layer with 16 5x5 filters (relu) -> 2x2 maxpool -> batch norm \n",
        "#-> conv layer with 32 5x5 filters (relu) -> 2x2 maxpool -> batch norm -> flatten\n",
        "#-> 256 dense layer (relu) -> batch norm -> 10 unit dense output layer (softmax)\n",
        "\n",
        "filter1, filter2, filter_size, dense, momentum = 16, 32, 5, 256, 0.99\n",
        "def cnn_grad(batch, truth, f1, b1, gamma1, beta1, mu1_MA, var1_MA, f2, b2, gamma2, beta2, mu2_MA, var2_MA, w1, b3, gamma3, beta3, mu3_MA, var3_MA, w2, b4):\n",
        "  size = batch.shape[0]\n",
        "  #first we pad the input with zeros\n",
        "  batch = np.pad(batch, ((0,0),(2,2),(2,2)))\n",
        "  #first convolutional layer \n",
        "  arr1 = np.empty((filter_size**2, size, 28, 28))\n",
        "  for i in range(filter_size**2):\n",
        "    arr1[i,:,:,:] = batch[:, i//5:i//5 + 28, i%5:i%5 + 28]\n",
        "  c1 = np.tensordot(f1, arr1, axes=((1),(0))) + b1.reshape(filter1,1,1,1) \n",
        "  c1 = relu(c1) \n",
        "  #first max pooling layer\n",
        "  s1 = filter1*size*196\n",
        "  z1 = np.arange(s1)\n",
        "  res1 = np.swapaxes(c1.reshape(filter1,size,14,2,14,2),3,4).reshape(s1,4)\n",
        "  arg1 = np.argmax(res1, axis=1)\n",
        "  mp1 = res1[z1, arg1].reshape(filter1,size,14,14)\n",
        "  #first batch normalisation\n",
        "  mu1 = np.mean(mp1, axis=(1,2,3))\n",
        "  m1 = size*196\n",
        "  xmu1 = mp1-mu1.reshape(filter1,1,1,1)\n",
        "  var1 =  np.sum(xmu1**2, axis=(1,2,3))/m1\n",
        "  invsd1 = 1/np.sqrt(var1.reshape(filter1,1,1,1) + 0.001)\n",
        "  x_hat1 = (mp1 - mu1.reshape(filter1,1,1,1)) * invsd1\n",
        "  bn1 = gamma1.reshape(filter1,1,1,1)*x_hat1 + beta1.reshape(filter1,1,1,1)\n",
        "  #update moving averages for mean and var (momentum=0.99)\n",
        "  mu1_MA = momentum*mu1_MA + (1-momentum)*mu1\n",
        "  var1_MA = momentum*var1_MA + (1-momentum)*var1\n",
        "  #pad with zeros\n",
        "  padded = np.pad(bn1, ((0,0),(0,0),(2,2),(2,2)))\n",
        "  #second convolutional layer \n",
        "  arr2=np.empty((filter_size**2,filter1,size,14,14))\n",
        "  for i in range(filter_size**2):\n",
        "    arr2[i,:,:,:,:] = padded[:,:, i//5:i//5 + 14, i%5:i%5 + 14]\n",
        "  c2 = np.tensordot(f2, arr2, axes=((1,2), (1,0))) + b2.reshape(filter2,1,1,1)\n",
        "  c2 = relu(c2)\n",
        "  #second max pooling layer\n",
        "  s2 = filter2*size*49\n",
        "  z2 = np.arange(s2)\n",
        "  res2 = np.swapaxes(c2.reshape(filter2,size,7,2,7,2),3,4).reshape(s2,4)\n",
        "  arg2 = np.argmax(res2, axis=1)\n",
        "  mp2 = res2[z2, arg2].reshape(filter2,size,7,7)\n",
        "  #second batch normalisation\n",
        "  m2 = 49*size\n",
        "  mu2 = np.mean(mp2, axis=(1,2,3))\n",
        "  xmu2 = mp2-mu2.reshape(filter2,1,1,1)\n",
        "  var2 =  np.sum(xmu2**2, axis=(1,2,3))/m2\n",
        "  invsd2 = 1/np.sqrt(var2.reshape(filter2,1,1,1) + 0.001)\n",
        "  x_hat2 = (mp2 - mu2.reshape(filter2,1,1,1)) * invsd2\n",
        "  bn2 = gamma2.reshape(filter2,1,1,1)*x_hat2 + beta2.reshape(filter2,1,1,1)\n",
        "  #update moving averages for mean and var (momentum=0.99)\n",
        "  mu2_MA = momentum*mu2_MA + (1-momentum)*mu2\n",
        "  var2_MA = momentum*var2_MA + (1-momentum)*var2\n",
        "  #flatten the output\n",
        "  flat = np.swapaxes(bn2, 0,1).reshape(size, -1)\n",
        "  # dense layer\n",
        "  d1 = np.matmul(w1, flat.T) + b3[:,np.newaxis]\n",
        "  a1 = relu(d1)\n",
        "  #batch norm\n",
        "  mu3 = np.mean(a1, axis=1) \n",
        "  xmu3 = a1-mu3[:,np.newaxis]\n",
        "  var3 = 1/size * np.sum(xmu3**2, axis=1)\n",
        "  invsd3 = 1/np.sqrt(var3.reshape(dense,1) + 0.001)\n",
        "  x_hat3 = (a1 - mu3.reshape(dense,1))*invsd3\n",
        "  bn3 = gamma3.reshape(dense,1)*x_hat3 + beta3.reshape(dense,1)\n",
        "  #moving averages\n",
        "  mu3_MA = momentum*mu3_MA + (1-momentum)*mu3\n",
        "  var3_MA = momentum*var3_MA + (1-momentum)*var3\n",
        "  #final layer with softmax activation\n",
        "  a2 = softmax(np.matmul(w2, bn3) + b4[:,np.newaxis])\n",
        "  #gradient via backprop - categorical cross entropy loss\n",
        "  inter1 = a2 - truth\n",
        "  db4 = np.sum(inter1, axis=1)\n",
        "  dw2 = np.matmul(inter1, bn3.T)\n",
        "  inter2 = np.matmul(w2.T, inter1)\n",
        "  dbeta3 = np.sum(inter2, axis=1)\n",
        "  dgam3 = np.sum(inter2*x_hat3, axis=1)\n",
        "  dxhat3 = inter2*gamma3[:,np.newaxis]\n",
        "  dsig3 = np.sum(dxhat3*xmu3, axis=1) * 0.5 * (invsd3.reshape(dense)**3)\n",
        "  dmu3 = np.sum(dxhat3*-invsd3, axis=1) + dsig3*np.sum(-2*xmu3, axis=1)/size\n",
        "  inter3 = (dxhat3*invsd3 + dsig3[:,np.newaxis]*2*xmu3/size + dmu3[:,np.newaxis]/size) * np.sign(a1)\n",
        "  db3 = np.sum(inter3, axis=1)\n",
        "  dw1 = np.matmul(inter3, flat)\n",
        "  inter4 = np.swapaxes(np.matmul(w1.T, inter3).T.reshape(size,filter2,7,7),0,1)\n",
        "  dbeta2 = np.sum(inter4, axis=(1,2,3))\n",
        "  dgam2 = np.sum(inter4*x_hat2, axis=(1,2,3))\n",
        "  dxhat2 = inter4*gamma2.reshape(filter2,1,1,1)\n",
        "  dsig2 = np.sum(dxhat2*xmu2, axis=(1,2,3)) * 0.5 * (invsd2.reshape(filter2)**3)\n",
        "  dmu2 = np.sum(dxhat2*-invsd2, axis=(1,2,3)) + dsig2*np.sum(-2*xmu2, axis=(1,2,3))/m2\n",
        "  inter5 = dxhat2*invsd2 + dsig2.reshape(filter2,1,1,1)*2*xmu2/m2 + dmu2.reshape(filter2,1,1,1)/m2\n",
        "  mp_grad2 = np.zeros((s2,4))\n",
        "  mp_grad2[z2,arg2] = inter5.ravel()\n",
        "  mp_grad2 = np.swapaxes(mp_grad2.reshape(filter2,size,7,7,2,2),3,4).reshape(filter2,size,14,14)\n",
        "  inter6 = mp_grad2*np.sign(c2)\n",
        "  db2 = np.sum(inter6, axis=(1,2,3))\n",
        "  df2 = np.swapaxes(np.tensordot(inter6, arr2, axes=((1,2,3),(2,3,4))),1,2)\n",
        "  f2_prime = np.rot90(f2.reshape(filter2,filter1,5,5), 2, axes=(2,3))\n",
        "  pad = np.pad(inter6, ((0,0),(0,0),(2,2),(2,2)))\n",
        "  sub = np.empty((filter_size**2,filter2,size,14,14))\n",
        "  for i in range(filter_size**2):\n",
        "    sub[i,:,:,:,:] = pad[:,:, i//5:i//5 + 14, i%5:i%5 + 14]\n",
        "  inter7 = np.tensordot(f2_prime.reshape(filter2,filter1,filter_size**2), sub, axes=((0,2),(1,0)))\n",
        "  dbeta1 = np.sum(inter7, axis=(1,2,3))\n",
        "  dgam1 = np.sum(inter7*x_hat1, axis=(1,2,3))\n",
        "  dxhat1 = inter7*gamma1.reshape(filter1,1,1,1)\n",
        "  dsig1 = np.sum(dxhat1*xmu1, axis=(1,2,3)) * 0.5 * (invsd1.reshape(filter1)**3)\n",
        "  dmu1 = np.sum(dxhat1*-invsd1, axis=(1,2,3)) + dsig1*np.sum(-2*xmu1, axis=(1,2,3))/m1\n",
        "  inter8 = dxhat1*invsd1 + dsig1.reshape(filter1,1,1,1)*2*xmu1/m1 + dmu1.reshape(filter1,1,1,1)/m1\n",
        "  mp_grad1 = np.zeros((s1,4))\n",
        "  mp_grad1[z1,arg1] = inter8.ravel()\n",
        "  mp_grad1 = np.swapaxes(mp_grad1.reshape(filter1,size,14,14,2,2),3,4).reshape(filter1,size,28,28)\n",
        "  inter9 = mp_grad1*np.sign(c1)\n",
        "  db1 = np.sum(inter9, axis=(1,2,3))\n",
        "  df1 = np.tensordot(inter9, arr1, axes=((1,2,3),(1,2,3)))\n",
        "  return [df1,db1,dgam1,dbeta1,df2,db2,dgam2,dbeta2,dw1,db3,dgam3,dbeta3,dw2,db4],mu1_MA,var1_MA,mu2_MA,var2_MA,mu3_MA,var3_MA\n",
        "  \n",
        "\n",
        "#vanilla gradient descent \n",
        "def gd(batch,truth,p,mu1,var1,mu2,var2,mu3,var3,learning_rate):\n",
        "  grad,mu1,var1,mu2,var2,mu3,var3 = cnn_grad(batch, truth,p[0],p[1],p[2],p[3],mu1, var1, p[4], p[5], p[6], p[7], mu2, var2, p[8], p[9], p[10], p[11], mu3, var3, p[12], p[13]) \n",
        "  p = [a - learning_rate*b for a,b in zip(p,grad)]\n",
        "  return p,mu1,var1,mu2,var2,mu3,var3\n",
        "\n",
        "def mini_batch_sgd(X, Y, epochs, batch_size):\n",
        "  p,mu1,var1,mu2,var2,mu3,var3 = [np.random.uniform(-np.sqrt(6/(filter_size**2+filter1)), np.sqrt(6/(filter_size**2+filter1)), (filter1, filter_size**2)),np.zeros(filter1),np.ones(filter1),np.zeros(filter1),np.random.uniform(-np.sqrt(6/(filter1*filter_size**2+filter2)), np.sqrt(6/(filter1*filter_size**2+filter2)), (filter2, filter1, filter_size**2)),np.zeros(filter2),np.ones(filter2),np.zeros(filter2), np.random.uniform(-np.sqrt(6/(filter2*49 + dense)),np.sqrt(6/(filter2*49 + dense)), (dense, filter2*49)),np.zeros(dense),np.ones(dense),np.zeros(dense),np.random.uniform(-np.sqrt(6/(dense+10)), np.sqrt(6/(dense+10)), (10,dense)),np.zeros(10)],0,1,0,1,0,1 \n",
        "  \n",
        "  #loop through entire dataset 'epochs' times\n",
        "  for i in range(epochs):\n",
        "    #in each epoch perform gradient descent on each mini batch\n",
        "    perm = np.random.permutation(X.shape[0])\n",
        "    X = X[perm, :, :]\n",
        "    Y = Y[:, perm]\n",
        "    for j in range(int(np.ceil(X.shape[0]/batch_size))):\n",
        "      batch = X[batch_size*j:batch_size*(j+1),:,:]\n",
        "      truth = Y[:, batch_size*j:batch_size*(j+1)]\n",
        "      p,mu1,var1,mu2,var2,mu3,var3 = gd(batch, truth, p, mu1, var1, mu2, var2, mu3, var3, 0.005)\n",
        "  return p,mu1,var1,mu2,var2,mu3,var3\n",
        "\n",
        "#train network\n",
        "p, mu1, var1, mu2, var2, mu3, var3 = mini_batch_sgd(train_X, Y.T, 16, 32)  \n",
        "\n",
        "#make predictions\n",
        "pred=np.empty(10000)\n",
        "for j in range(10):\n",
        "  size = test_X[j*1000:1000*(j+1)].shape[0]\n",
        "  batch = np.pad(test_X[1000*j:1000*(j+1)], ((0,0),(2,2),(2,2)))\n",
        "  arr1 = np.empty((25, size, 28, 28))\n",
        "  for i in range(25):\n",
        "     arr1[i,:,:,:] = batch[:, i//5:i//5 + 28, i%5:i%5 + 28]\n",
        "  c1 = np.tensordot(p[0], arr1, axes=((1),(0))) + p[1].reshape(filter1,1,1,1) \n",
        "  c1 = relu(c1) \n",
        "  mp1 = c1.reshape(filter1,size,14,2,14,2).max(axis=(3,5))\n",
        "  x_hat1 = (mp1 - mu1.reshape(filter1,1,1,1)) / np.sqrt(var1.reshape(filter1,1,1,1))\n",
        "  bn1 = p[2].reshape(filter1,1,1,1)*x_hat1 + p[3].reshape(filter1,1,1,1)\n",
        "  padded = np.pad(bn1, ((0,0),(0,0),(2,2),(2,2)))\n",
        "  arr2=np.empty((25,filter1,size,14,14))\n",
        "  for i in range(25):\n",
        "    arr2[i,:,:,:,:] = padded[:,:, i//5:i//5 + 14, i%5:i%5 + 14]\n",
        "  c2 = np.tensordot(p[4], arr2, axes=((1,2), (1,0))) + p[5].reshape(filter2,1,1,1)\n",
        "  c2 = relu(c2)\n",
        "  mp2 = c2.reshape(filter2,size,7,2,7,2).max(axis=(3,5))\n",
        "  x_hat2 = (mp2 - mu2.reshape(filter2,1,1,1)) / np.sqrt(var2.reshape(filter2,1,1,1))\n",
        "  bn2 = p[6].reshape(filter2,1,1,1)*x_hat2 + p[7].reshape(filter2,1,1,1)\n",
        "  flat = np.swapaxes(bn2, 0,1).reshape(size, -1)\n",
        "  d1 = np.matmul(p[8], flat.T) + p[9][:,np.newaxis]\n",
        "  a1 = relu(d1)\n",
        "  x_hat3 = (a1 - mu3.reshape(dense,1)) / np.sqrt(var3.reshape(dense,1))\n",
        "  bn3 = p[10].reshape(dense,1)*x_hat3 + p[11].reshape(dense,1)  \n",
        "  a2 = softmax(np.matmul(p[12], bn3) + p[13][:,np.newaxis])\n",
        "  pred[j*1000:1000*(j+1)] = np.argmax(a2, axis=0)\n",
        "\n",
        "sum(pred==test_y)/test_y.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9898"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XmSbhgvTF64"
      },
      "source": [
        "check tensorflow provides a similar answer with the same architecture, batch size, epochs, loss etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabLVkox4F1V",
        "outputId": "072cafbe-ae44-49b8-88ee-84bc359e9f02"
      },
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(16, 5, padding='same', input_shape= (28,28,1), activation='relu'))\n",
        "cnn.add(MaxPooling2D(2))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Conv2D(32, 5, padding='same', activation='relu'))\n",
        "cnn.add(MaxPooling2D(2))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(256, 'relu'))\n",
        "cnn.add(BatchNormalization())\n",
        "cnn.add(Dense(10, activation='softmax'))\n",
        "cnn.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "cnn.fit(train_X[:,:,:,np.newaxis], Y, batch_size=32, epochs=16, verbose=0)\n",
        "pred = cnn.predict(test_X[:,:,:,np.newaxis])\n",
        "sum(np.argmax(np.array(pred), axis=1)==test_y)/test_y.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9912"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}