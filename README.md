# mikit-learn
Coding 7 different classification algorithms used in scikit-learn and TensorFlow, to learn Python. The 7 algorithms are
1. K nearest Neighbours
2. Multinomial logistic regression
3. Support vector classifier
4. Decision tree
5. Random forest
6. Multilayer perceptron (with data augmentation)
7. Convolutional neural network (with batch normalisation). 



Some of the things I learnt:
* OOP in Python (constructors, inheritance, composition, encapsulation).
* Generators: for a memory efficient implementation of k nearest neighbours.
* Cython: to speed up the implementation of support vector classifier.
* Recursion: to program the decision tree.
* Multiprocessing: to parallelise the random forest algorithm.
* Context managers: used with multiprocessing to ensure processes are always closed.
* Metaclasses: using abstract base classes to force our classifiers to implement certain methods.
* Magic methods: using __ eq __ to allow comparison of mine and scikit's classifiers.
* NumPy: allows us to vectorise computations. Almost everything is done in NumPy for efficiency.
* Pytest: writing unit tests in Python.
* PEP 8: how to write readable and well-documented code.
* A thorough understanding of how all of these algorithms work.
