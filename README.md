# mikit-learn
Coding 7 different classification algorithms used in scikit-learn and TensorFlow, to learn Python. Some of the things I learnt:
* OOP in Python (constructors, inheritance, composition, encapsulation).
* Generators: for a memory efficient implementation of k nearest neighbours.
* Cython: to speed up the implementation of support vector classifier.
* Recursion: to program the decision tree.
* Multiprocessing: to parallelise the random forest algorithm.
* Context managers: used with multiprocessing to ensure processes are always closed.
* Metaclasses: using abstract base classes to force our classifiers to implement certain methods.
* Magic methods: using __ eq __ to allow comparison of mine and scikit's classifiers.
* NumPy: allows us to vectorise computations. Almost everything is done in NumPy for efficiency.
* PEP 8: how to write readable and well-documented code.
* A thorough understanding of how all of these algorithms work.
